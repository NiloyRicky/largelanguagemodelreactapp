# ğŸ§  No-Code AI Workflow Builder

A **visual workflow builder** that lets you create AI pipelines by dragging and connecting nodes like **User Query**, **Knowledge Base**, **LLM Engine**, and **Output**.  
This project allows you to upload documents (e.g., resumes), embed them locally using **ChromaDB**, and query them with **local or OpenAI models**.

---

## ğŸš€ Features

- ğŸ¨ **Visual Node-based Workflow**
  - Build pipelines with drag-and-drop nodes in ReactFlow
  - Connect queries â†’ knowledge base â†’ LLM â†’ output

- ğŸ“‚ **Knowledge Base**
  - Upload PDFs or text files
  - Store embeddings in **ChromaDB** for fast similarity search

- ğŸ¤– **LLM Engine**
  - Supports both **OpenAI API models** (gpt-3.5, gpt-4)  
  - Supports **Local HuggingFace models** (e.g., GPT-2) â€” runs free without tokens

- ğŸ§¾ **Output Node**
  - Displays AI-generated answers directly in the workflow UI

- ğŸ”— **Custom Workflow Execution**
  - Automatically parses nodes + edges
  - Passes query â†’ retrieves context â†’ generates LLM answer â†’ outputs result

---

## ğŸ› ï¸ Tech Stack

### Frontend
- âš›ï¸ React + Vite
- ğŸ¨ ReactFlow (for node editor)
- ğŸ“¦ Axios (for API calls)

### Backend
- âš¡ FastAPI (Python)
- ğŸ“‚ ChromaDB (vector storage)
- ğŸ§  HuggingFace Transformers (local models like GPT-2)
- (Optional) OpenAI API (cloud-based LLMs + embeddings)

### Database
- SQLite (default) for Chroma storage

---
## ğŸ“ Project Structure

/frontend
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ pages/
â”‚ â”‚ â”œâ”€â”€ UserQueryNode.jsx
â”‚ â”‚ â”œâ”€â”€ KnowledgeBaseNode.jsx
â”‚ â”‚ â”œâ”€â”€ LLMEngineNode.jsx
â”‚ â”‚ â”œâ”€â”€ OutputNode.jsx
â”‚ â””â”€â”€ StackBuilder.jsx
â””â”€â”€ api.js

/backend/
â”œâ”€â”€ main.py
â”œâ”€â”€ db.py
â”œâ”€â”€ routes/
â”‚ â”œâ”€â”€ upload.py
â”‚ â”œâ”€â”€ workflow.py
â”œâ”€â”€ schemas.py
â””â”€â”€ services/
â”œâ”€â”€ embeddings.py
â”œâ”€â”€ llm.py


---

## âš™ï¸ Installation & Setup

### 1. Clone the repository
```bash
git clone https://github.com/NiloyRicky/largelanguagemodelreactapp.git
cd your-repo-name

2. Backend Setup (FastAPI + Chroma + HuggingFace)
cd backend
python -m venv venv
source venv/bin/activate   # (Windows: venv\Scripts\activate)
pip install -r requirements.txt

Create a requirements.txt with:

fastapi
uvicorn
chromadb
sqlalchemy
pydantic
transformers
torch

Run Backend:
uvicorn app.main:app --reload --port 8000
Backend runs at  http://localhost:8000

Frontend Set up (React+Vite)
cd frontend
npm install
npm run dev


Workflow Example

Drag a User Query Node â†’ type: "What are my achievements?"

Drag a Knowledge Base Node â†’ upload resume.pdf

Drag an LLM Engine Node â†’ select local GPT-2 or OpenAI

Drag an Output Node

Connect them:
User Query â†’ Knowledge Base â†’ LLM Engine â†’ Output

Click Run Workflow

ğŸ‰ See the generated response in the Output node.

ğŸ’¾ File & Embedding Storage

Uploaded files â†’ stored in backend /uploads/

Embeddings â†’ stored in ChromaDB (default SQLite inside .chromadb/)

Local models â†’ cached by HuggingFace in ~/.cache/huggingface/

ğŸš§ Roadmap / Next Steps

 Support for more HuggingFace models (e.g., LLaMA 2, Mistral)

 Fine-tuning embeddings per project

 Multi-document context retrieval

 Workflow export/import as JSON

 Authentication for multi-user support

ğŸ¤ Contributing

Contributions are welcome!
Please fork the repo and create a PR with clear commit messages.

ğŸ“œ License

MIT License Â© 2025 Niloy Mondal









